# -*- coding: utf-8 -*-
"""Sentiment_Analysis_on_Flipkart_Product (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fjckgYH9ALsVn9K9tlbnoyQy76Wk1CwA

# **Team MoodMasters NLP Hub**
<img src="https://github.com/yaznhijazii/FlipkartNLP/blob/main/IMG_7579.PNG?raw=true" alt="Alt Text" width="300"/>


## Welcome Team MoodMasters!

Greetings Team MoodMasters! ðŸ‘‹ Get ready to explore the fascinating realm of Natural Language Processing (NLP) and sentiment analysis. Meet our stellar team:

- **1. Yazan Hijazi**
- **2. Mohammad Bata**
- **3. Saleh Khalaf**
- **4. Omar Khaled**


Let's collectively master the art of mood analysis! ðŸŒŸðŸ“ŠðŸ”®

#**Analyzing Flipkart Product Reviews with TextBlob**
<img src="https://github.com/yaznhijazii/FlipkartNLP/blob/main/1_Ud1zM4dy9e0Djy9syWg7BA.png?raw=true" alt="Alt Text" width="300"/>

#**Introduction To Flipkart**
Flipkart, a leading e-commerce platform, hosts a vast array of products, attracting millions of customers who provide valuable feedback through reviews. Analyzing these reviews is crucial for understanding customer sentiments and extracting meaningful insights.

In this Colab notebook, we'll explore the sentiment analysis of Flipkart product reviews using the TextBlob library.
#**Introduction To TextBlob library**

TextBlob is a powerful Python library built on top of NLTK and Pattern libraries, designed for processing textual data. It simplifies various natural language processing (NLP) tasks, including part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.

Our goal is to leverage TextBlob to perform a comprehensive analysis of Flipkart product reviews. We'll cover steps such as POS tagging, lemmatization, parsing, N-gram analysis, sentiment analysis, and word/phrase frequency analysis. Additionally, we'll utilize Spacy for spelling correction to enhance the accuracy of our text data.

Let's dive into the fascinating world of NLP and sentiment analysis to gain valuable insights into the sentiments expressed by Flipkart customers in their product reviews!

# **Download Library**
**!pip install textblob:** Installs the TextBlob library, a simple NLP (Natural Language Processing) library for processing textual data and performing common NLP tasks like sentiment analysis.

**!python -m spacy download en_core_web_sm:** is used to download the English language model "en_core_web_sm" for the spaCy natural language processing library in Python.
"""

!pip install textblob

!python -m spacy download en_core_web_sm

"""# **Importing Libraries**

####Text Processing and Analysis
- `TextBlob` and `Word` from `textblob`: Used for natural language processing tasks such as sentiment analysis and lemmatization.

####Data Manipulation
- `pandas as pd`: A library for handling and analyzing tabular data.

####Visualization
- `matplotlib.pyplot as plt` and `seaborn as sns`: Libraries for basic and statistical data visualization, respectively.

####Machine Learning
- `TfidfVectorizer` and `CountVectorizer` from `sklearn.feature_extraction.text`: Tools for converting text data to numerical representations.
- `train_test_split` from `sklearn.model_selection`: Function for splitting data into training and testing sets.
-`MultinomialNB` in scikit-learn is a classifier based on Bayes' theorem, suitable for discrete data like word counts. It assumes independence between features, making it commonly used in text classification.
- `accuracy_score` and `classification_report` from `sklearn.metrics`: Metrics for evaluating classification models.

####Advanced Natural Language Processing
- `spacy`: An open-source library for advanced natural language processing tasks.

####Interactive Widgets
- `ipywidgets as widgets`: A library for creating interactive user interfaces.

####Display
- `display` from `IPython.display`: A function for displaying objects in the IPython environment.

"""

from textblob import TextBlob, Word
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import spacy
import ipywidgets as widgets
import string
from IPython.display import display

"""# **Read Data**

In this section, we perform data cleaning tasks. One crucial step is handling null values in the dataset. To ensure the integrity of our analysis, we have removed any rows or columns containing null values.

"""

file_path = "/content/Flipkart.csv"
df= pd.read_csv(file_path, encoding='ISO-8859-1')
df

df.info()

df.isnull().sum()

df.dropna(inplace=True)

df.isnull().sum()

"""# **Preprocessing Step**
Introduction to Preprocessing:
Preprocessing is a vital data preparation stage, especially in natural language processing (NLP) and machine learning, involving tasks like text cleaning and transformation to optimize data for analysis. It aims to enhance data quality and facilitate better model performance by addressing issues such as noise, irregularities, and unnecessary complexity.

**Loading SpaCy Model:**

Loads the English language spaCy model for natural language processing.

**Defining Stop Words:**

Creates a set of stop words including common English words and additional negation-related terms.

**Text Cleaning Function:**

A function that performs several text cleaning operations on a DataFrame column.

**Column Type Conversion:**

Converts the data type of the specified DataFrame column to string.

**Lowercasing Text:**

Converts all text in the DataFrame column to lowercase.

**Removing Punctuation:**

Removes punctuation from the text in the DataFrame column.

**Stripping Whitespace:**

Removes leading and trailing whitespaces from the text in the DataFrame column.

**Removing Stop Words:**

Removes common stop words from the text in the DataFrame column.

**Lemmatization:**

Performs lemmatization on the text in the DataFrame column, reducing words to their base form.




"""

nlp = spacy.load("en_core_web_sm")
stop_words = spacy.lang.en.stop_words.STOP_WORDS | {'not', 'no', 'never', 'none', 'nothing', 'nowhere', 'nor', 'neither', 'cannot'}

def clean_column(df, column):
    df[column] = df[column].astype(str)
    df[column] = df[column].str.lower()
    df[column] = df[column].str.translate(str.maketrans('', '', string.punctuation))
    df[column] = df[column].str.strip()
    df[column] = df[column].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))
    df[column] = df[column].apply(lambda sentence: ' '.join([token.lemma_ for token in nlp(sentence)]))

    return df[column]

df['CleanSummary'] = clean_column(df, 'Summary')

"""# **Create Textblob**
TextBlob is a Python library that simplifies natural language processing tasks, and here it evaluates the sentiment of cleaned textual summaries. The resulting sentiment scores offer insights into the overall emotional tone, distinguishing between positive, negative, or neutral sentiments within the provided text data.

"""

df['TextBlob'] = df['CleanSummary'].apply(lambda summary: TextBlob(summary).sentiment)

"""# **Sentiment analysis**
<img src="https://github.com/yaznhijazii/FlipkartNLP/blob/main/Social-Media-Sentiment-Analysis.jpg?raw=true" alt="Alt Text" width="300"/>

Determine the sentiment (positive, negative, neutral) expressed in a piece of text using TextBlob's sentiment analysis capabilities.
"""

df['Sentiment'] = df['TextBlob'].apply(lambda textblob: 'Positive' if textblob.polarity > 0 else ('Neutral' if textblob.polarity == 0 else 'Negative'))
sentiment_distribution = df['Sentiment'].value_counts()
print("Sentiment Distribution:")
print(sentiment_distribution)

plt.figure(figsize=(8, 6))
sns.countplot(x='Sentiment', data=df)
plt.title("Sentiment Distribution")
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.show()

"""# **N-Gram**
N-grams are contiguous sequences of n items (words in the context of NLP). TextBlob facilitates the extraction of N-grams, helping to capture patterns and relationships in the text.

"""

X_train, X_test, y_train, y_test = train_test_split(df['CleanSummary'], df['Sentiment'], test_size=0.2, random_state=42)

from sklearn.utils.class_weight import compute_sample_weight

class_labels = {'Negative': 0, 'Neutral': 1, 'Positive': 2}
y_train_numeric = y_train.map(class_labels)

# Define class weights for each class label
class_weights = {0: 1, 1: 5, 2: 1}

# Compute sample weights based on class weights for training data
sample_weights_train = compute_sample_weight(class_weights, y_train_numeric)
vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

"""# **Model Building**
a Multinomial Naive Bayes model is trained using X_train_vectorized and y_train, representing the vectorized training data and corresponding labels.
"""

model = MultinomialNB()
model.fit(X_train_vectorized, y_train_numeric, sample_weight=sample_weights_train)
y_pred_numeric = model.predict(X_test_vectorized)
print("Classification Report with Class Weights:")
print(classification_report(y_test_numeric, y_pred_numeric, target_names=class_labels.keys()))

"""# **Let's Try The code!**

#**You can use these sentences !**
**Positive Sentiment:**

"I love this product! It's amazing."

**Negative Sentiment:**

"This product is terrible."

**Neutral Sentiment:**

"This is a standard product."

"""

# Import necessary libraries
from ipywidgets import interact, widgets

# Function to analyze sentiment
def analyze_sentiment(text):
    cleaned_text = clean_column(pd.DataFrame({'Summary': [text]}, index=[0]), 'Summary')[0]
    tb_sentiment = TextBlob(cleaned_text).sentiment
    sentiment = 'Positive' if tb_sentiment.polarity > 0 else ('Neutral' if tb_sentiment.polarity == 0 else 'Negative')
    return sentiment

# GUI components
text_input = widgets.Text(value='', placeholder='Enter a sentence...', description='Input:')
output = widgets.Output()

# Function to handle button click
def on_button_click(b):
    with output:
        output.clear_output()
        sentence = text_input.value
        sentiment = analyze_sentiment(sentence)
        print(f"Input Sentence: {sentence}")
        print(f"Sentiment: {sentiment}")

# Button to trigger sentiment analysis
button = widgets.Button(description='Analyze Sentiment')
button.on_click(on_button_click)

# Display the GUI
display(text_input, button, output)

"""# My GitHub Project

Check out my project on GitHub: [My Repository](https://github.com/yaznhijazii/FlipkartNLP/tree/main)

"""